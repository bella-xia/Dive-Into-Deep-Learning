{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586a381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b73f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNScratch(d2l.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W_xh = nn.Parameter(\n",
    "        torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.W_hh = nn.Parameter(\n",
    "        torch.randn(num_hiddens, num_hiddens) * sigma)\n",
    "        self.b_h = nn.Parameter(torch.zeros(num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a19ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNScratch)\n",
    "def forward(self, inputs, state=None):\n",
    "    if state is None:\n",
    "        state = torch.zeros((inputs.shape[1], self.num_hiddens),\n",
    "                            device = inputs.device)\n",
    "    else:\n",
    "        state, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        state = torch.tanh(torch.matmul(X, self.W_xh) + \n",
    "                          torch.matmul(state, self.W_hh) +\n",
    "                          self.b_h)\n",
    "        outputs.append(state)\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86b935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "rnn = RNNScratch(num_inputs, num_hiddens)\n",
    "X = torch.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b0d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len(a, n):\n",
    "    assert len(a) == n, \\\n",
    "    f'list\\'s length {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):\n",
    "    assert a.shape == shape, \\\n",
    "    f'tensor\\'s shape {a.shape} != expected shape {shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a12163",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_len(outputs, num_steps)\n",
    "check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "check_shape(state, (batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e17163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLMScratch(d2l.Classifier):\n",
    "    def __init__(self, rnn, vocab_size, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.W_hq = nn.Parameter(\n",
    "        torch.randn(\n",
    "        self.rnn.num_hiddens, self.vocab_size) * self.rnn.sigma)\n",
    "        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=True)\n",
    "        return l\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109eddf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
